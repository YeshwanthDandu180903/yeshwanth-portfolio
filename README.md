# Yeshwanth Dandu | Data Scientist Portfolio ğŸš€

Welcome to my personal portfolio! This project features a **modern, responsive frontend** deployed on Vercel and a **powerful RAG AI Backend** deployed on Render, creating an intelligent chatbot that can answer questions about my experience, projects, and skills.

![Portfolio Preview](images/portfolio_home.png)

## ğŸŒŸ Live Demo

- **Frontend (Portfolio)**: [Deployed on Vercel](https://your-vercel-app-url.vercel.app)
- **Backend (AI Agent)**: [Deployed on Render](https://rag-backend-xv31.onrender.com) (API Service)

---

## ğŸ—ï¸ System Architecture

This portfolio implements a **full-stack RAG (Retrieval-Augmented Generation)** system with a clean separation between frontend and backend:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CLIENT SIDE (Vercel)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Portfolio Website (Static Site)                          â”‚  â”‚
â”‚  â”‚  â€¢ HTML5 + CSS3 (Glassmorphism Design)                    â”‚  â”‚
â”‚  â”‚  â€¢ Vanilla JavaScript                                     â”‚  â”‚
â”‚  â”‚  â€¢ Bootstrap 5                                            â”‚  â”‚
â”‚  â”‚  â€¢ Responsive UI with Dark/Light Mode                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â–²                                  â”‚
â”‚                              â”‚ User Interaction                 â”‚
â”‚                              â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Chat Interface                                           â”‚  â”‚
â”‚  â”‚  â€¢ Sends user queries via HTTPS POST to /chat             â”‚  â”‚
â”‚  â”‚  â€¢ Receives AI-generated responses                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ HTTPS API Calls
                              â”‚ (JSON Request/Response)
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SERVER SIDE (Render)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  FastAPI Backend (main.py)                                â”‚  â”‚
â”‚  â”‚  â€¢ CORS-enabled REST API                                  â”‚  â”‚
â”‚  â”‚  â€¢ Endpoints: /, /chat, /linkedin_posts                   â”‚  â”‚
â”‚  â”‚  â€¢ Initializes PortfolioAgent on startup                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â”‚                                  â”‚
â”‚                              â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  RAG Agent (rag_agent.py)                                 â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  1. Query Processing                                      â”‚  â”‚
â”‚  â”‚     â””â”€ Receives user question                             â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  2. Context Retrieval (FAISS Vector Store)                â”‚  â”‚
â”‚  â”‚     â”œâ”€ Embeddings: BAAI/bge-small-en-v1.5                 â”‚  â”‚
â”‚  â”‚     â”œâ”€ Similarity Search (Top-K=6 documents)              â”‚  â”‚
â”‚  â”‚     â””â”€ Retrieves relevant resume/project chunks           â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  3. Prompt Engineering                                    â”‚  â”‚
â”‚  â”‚     â”œâ”€ System Prompt (context_engineering_prompt.md)      â”‚  â”‚
â”‚  â”‚     â”œâ”€ Retrieved Context                                  â”‚  â”‚
â”‚  â”‚     â””â”€ User Query                                         â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  4. LLM Generation (Groq API)                             â”‚  â”‚
â”‚  â”‚     â”œâ”€ Model: Llama-3.3-70b-versatile                     â”‚  â”‚
â”‚  â”‚     â”œâ”€ Temperature: 0.7                                   â”‚  â”‚
â”‚  â”‚     â””â”€ Max Tokens: 1024                                   â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  5. Response Formatting                                   â”‚  â”‚
â”‚  â”‚     â””â”€ Clean, plain-text response (no markdown)           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â”‚                                  â”‚
â”‚                              â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Data Sources                                             â”‚  â”‚
â”‚  â”‚  â€¢ FAISS Vector Index (faiss_index/)                      â”‚  â”‚
â”‚  â”‚  â€¢ Resume & Portfolio Documents                           â”‚  â”‚
â”‚  â”‚  â€¢ Project Descriptions                                   â”‚  â”‚
â”‚  â”‚  â€¢ Skills & Experience Data                               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Architecture Components Explained

#### **Frontend (Vercel)**
- **Static Site Hosting**: Deployed as a static site for fast loading and zero server costs
- **Modern UI/UX**: Glassmorphism design with smooth animations and responsive layout
- **API Integration**: JavaScript fetch calls to backend `/chat` endpoint
- **Real-time Chat**: Interactive chatbot interface with typing indicators

#### **Backend (Render)**
- **FastAPI Server**: High-performance async Python web framework
- **CORS Configuration**: Allows cross-origin requests from Vercel frontend
- **Lazy Loading**: Vector store loads on first request to reduce cold start time
- **Error Handling**: Graceful fallbacks if RAG system fails to initialize

#### **RAG System Pipeline**
1. **Embedding Model**: Uses `BAAI/bge-small-en-v1.5` via FastEmbed for efficient vector embeddings
2. **Vector Store**: FAISS (Facebook AI Similarity Search) for fast semantic search
3. **Retrieval**: Top-K similarity search retrieves most relevant document chunks
4. **Context Injection**: Retrieved context is injected into the system prompt
5. **LLM Generation**: Groq's Llama-3.3-70b generates contextually-aware responses
6. **Response Delivery**: JSON response sent back to frontend

### Key Features
- âœ… **Intelligent Responses**: RAG ensures answers are grounded in actual portfolio data
- âœ… **Fast Retrieval**: FAISS enables sub-second semantic search
- âœ… **Scalable**: Stateless API design allows horizontal scaling
- âœ… **Cost-Effective**: Free-tier deployments on Vercel + Render
- âœ… **Maintainable**: Clean separation of concerns with modular architecture

## ğŸ› ï¸ Tech Stack

-   **Frontend**: HTML, CSS (Glassmorphism), JavaScript, Bootstrap 5.
-   **Backend**: Python, FastAPI, LangChain, Groq.
-   **Deployment**: Vercel (UI), Render (API).

## ğŸš€ Local Development

To run the frontend locally:
1.  Clone the repo.
2.  Open `index.html` in your browser (or use Live Server).
3.  The chat will automatically connect to the **live Render backend**.

(No need to run the Python backend locally unless you are developing it!)

## ğŸ“¬ Contact

-   **Email**: [yeshwanthdandu2003@gmail.com](mailto:yeshwanthdandu2003@gmail.com)
-   **LinkedIn**: [Yeshwanth Dandu](https://linkedin.com/in/yeshwanthdandu)
-   **GitHub**: [YeshwanthDandu180903](https://github.com/YeshwanthDandu180903)

---
&copy; 2026 Yeshwanth Dandu.
